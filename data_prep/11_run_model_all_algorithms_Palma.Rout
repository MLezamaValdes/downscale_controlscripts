
R version 3.6.0 (2019-04-26) -- "Planting of a Tree"
Copyright (C) 2019 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> 
> y=1
> m=1
> # 
> # loc="Palma"
> testing=TRUE
> print("loading Palma libs and paths")
[1] "loading Palma libs and paths"
> library(raster)
Loading required package: sp
> library(rgdal)
rgdal: version: 1.4-4, (SVN revision 833)
 Geospatial Data Abstraction Library extensions to R successfully loaded
 Loaded GDAL runtime: GDAL 3.0.0, released 2019/05/05
 Path to GDAL shared files: 
 GDAL binary built with GEOS: TRUE 
 Loaded PROJ.4 runtime: Rel. 6.0.0, March 1st, 2019, [PJ_VERSION: 600]
 Path to PROJ.4 shared files: (autodetected)
 Linking to sp version: 1.3-1 
> datpath <- "/scratch/tmp/llezamav/satstacks/"
> aoipath <- "/scratch/tmp/llezamav/aoi/"
> time_range <- readRDS("/scratch/tmp/llezamav/time_range.rds")
> cddir <- "/scratch/tmp/llezamav/satstacks/"
> iahsrespath <- "/scratch/tmp/llezamav/ia_hs_res/"
> swiroutpath <- paste0(datpath, "swir/")
> time_range <- readRDS("/scratch/tmp/llezamav/time_range.rds")
> outpath <- "/scratch/tmp/llezamav/modelling/"
> 
> expath <- "/scratch/tmp/llezamav/stack_extraction/"
> library(parallel)
> library(doParallel)
Loading required package: foreach
Loading required package: iterators
> library(CAST,lib.loc="/home/l/llezamav/R/")
Registered S3 methods overwritten by 'ggplot2':
  method         from 
  [.quosures     rlang
  c.quosures     rlang
  print.quosures rlang
> library(caret,lib.loc="/home/l/llezamav/R/")
Loading required package: lattice
Loading required package: ggplot2
> library(gbm,lib.loc="/home/l/llezamav/R/")
Loaded gbm 2.1.5
> 
> library(Cubist,lib.loc="/home/l/llezamav/R/")
> library(pls,lib.loc="/home/l/llezamav/R/")

Attaching package: ‘pls’

The following object is masked from ‘package:caret’:

    R2

The following object is masked from ‘package:stats’:

    loadings

> library(kernlab,lib.loc="/home/l/llezamav/R/")

Attaching package: ‘kernlab’

The following object is masked from ‘package:ggplot2’:

    alpha

The following objects are masked from ‘package:raster’:

    buffer, rotated

> print("libraries loaded")
[1] "libraries loaded"
> 
> ym <- substring(time_range[[y]][[m]][[1]][[1]], 1, 7)
> `%notin%` <- Negate(`%in%`)
> print("notin done")
[1] "notin done"
> 
> print("loading rds")
[1] "loading rds"
> train <- readRDS(paste0(expath, "train_DI__2019-01.rds"))
> print("loaded train rds")
[1] "loaded train rds"
> 
> if(testing){
+   ### just for testing ###############
+   n <- 15000
+   
+   # only if subset
+   trainsubset <- train[sample(nrow(train),n), ]
+   saveRDS(trainsubset, paste0(outpath, "train_", ym, "_subset_", n, ".rds"))
+   train <- trainsubset 
+   
+   testsubset <- readRDS(paste0(expath, "test_ds_2019-01.rds"))
+ } else {
+   n <- nrow(train)
+ }
> 
> #################
> 
> kval <- min(length(unique(train$time_num)), length(unique(train$spatialblocks)))
> 
> # split training cuarter into various blocks for cv during training
> foldids <- CreateSpacetimeFolds(train, spacevar="spatialblocks", timevar = "time_num",
+                                 k=kval,seed=100)
> 
> (trainlength <- sapply(seq(foldids$indexOut), function(i){
+   length(foldids$indexOut[[i]])
+ }))
[1] 126 275 341 132 266 388  66  18
> 
> set.seed(100)
> 
> metric <- "RMSE" # Selection of variables made by either Rsquared or RMSE
> # gbm didn't work
> methods <- c("rf",
+              "gbm",
+              "nnet",
+              "svmLinear")
> withinSE <- FALSE # favour models with less variables or not?
> response <- train$Landsat
> predictors <- train[,c("Modis","ia", "hs", "dem", 
+                        "slope", "aspect", "TWI", 
+                        "soilraster", "landcoverres", 
+                        "swir6", "swir7")]
> length(predictors)
[1] 11
> 
> for (i in 1:length(methods)){
+   
+   tctrl <- trainControl(method="cv", 
+                         savePredictions = TRUE,
+                         returnResamp = "all",
+                         verboseIter=TRUE,
+                         index=foldids$index,
+                         indexOut=foldids$indexOut)
+   
+   
+   method <- methods[i]
+   print(method)
+   tuneLength <- 2
+   tuneGrid <- NULL
+   
+   if (method=="rf"){
+     #   tuneLength <- 1
+     tuneGrid <- expand.grid(mtry=seq(2,3))
+     # Create A Data Frame From All Combinations Of Factor Variables, 
+     # mtry: Number of variables randomly sampled as candidates at each split
+   }
+   if (method=="gbm"){
+     #tuneLength <- 10
+     predictors <- data.frame(scale(train[,c("Modis","ia", "hs", "dem",
+                                             "slope", "aspect", "TWI",
+                                             "soilraster",
+                                             "swir6", "swir7")]))
+     
+     tctrl <- trainControl(method="repeatedcv",
+                           number=kval,
+                           repeats=kval,
+                           savePredictions = TRUE,
+                           returnResamp = "all",
+                           verboseIter=TRUE,
+                           index=foldids$index,
+                           indexOut=foldids$indexOut)
+     
+   }
+   if (method=="nnet"){
+     #   tuneLength <- 1
+     predictors <- data.frame(scale(predictors))
+     tuneGrid <- expand.grid(size = seq(2,ncol(predictors),2),
+                             decay = seq(0,0.1,0.025))
+   }
+   
+   if (method=="svmLinear"){ # C controls how large the support vectors, i.e. margins are
+     #   tuneLength <- 1
+     tuneGrid <- expand.grid(C= 2^c(0:4))
+   }
+   
+   
+   cores <- detectCores()
+   cl <- makeCluster(cores-3)
+   registerDoParallel(cl)
+   
+   
+   
+   if(method=="gbm"){ # importance = TRUE kills it
+     ffs_model <- ffs(predictors,response, 
+                      method="gbm", 
+                      trControl=tctrl,
+                      tuneGrid=tuneGrid,
+                      withinSE = FALSE,
+                      tuneLength=tuneLength,           
+                      metric=metric)
+     
+   } else {
+     ffs_model <- ffs(predictors,
+                      response,
+                      metric=metric,
+                      withinSE = withinSE,
+                      method = method,
+                      importance =TRUE,
+                      tuneLength = tuneLength,
+                      tuneGrid = tuneGrid,
+                      trControl = tctrl,
+                      trace = FALSE, #relevant for nnet
+                      linout = TRUE) #relevant for nnet
+     
+     
+   }
+   
+   save(ffs_model,file=paste0(outpath,"ffs_model_",method,"_", n, ".RData"))
+   stopCluster(cl)
+ }
[1] "rf"
[1] "model using Modis,ia will be trained now..."
Aggregating results
Selecting tuning parameters
Fitting mtry = 3 on full training set
[1] "maximum number of models that still need to be trained: 99"
[1] "model using Modis,hs will be trained now..."
Aggregating results
Selecting tuning parameters
Fitting mtry = 2 on full training set
[1] "maximum number of models that still need to be trained: 98"
[1] "model using Modis,dem will be trained now..."
